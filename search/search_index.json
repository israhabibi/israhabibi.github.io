{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to My Tech Tutorials","text":"<p>Hello! I'm [Your Name], a passionate tech enthusiast dedicated to sharing knowledge through comprehensive tutorials. My goal is to help others learn and grow in the ever-evolving tech world.</p>"},{"location":"#about-me","title":"About Me","text":"<p>I enjoy exploring new technologies and creating guides that simplify complex concepts. Whether you're here to learn something new or get a quick refresher, I hope you find these resources helpful.</p> <p>Thank you for visiting, and happy learning!</p> <p></p>"},{"location":"From%20LLM/pyspark-hudi-minio/","title":"PySpark + Hudi + MinIO Local Development Setup","text":""},{"location":"From%20LLM/pyspark-hudi-minio/#emr-73-compatible-environment","title":"EMR 7.3 Compatible Environment","text":""},{"location":"From%20LLM/pyspark-hudi-minio/#project-goal","title":"\ud83c\udfaf Project Goal","text":"<p>Set up a local development environment that mimics AWS EMR 7.3 for testing PySpark with Hudi, using Docker to avoid Java version conflicts and dependency management issues. The setup includes MinIO for S3-compatible storage and volume mounting for local code development.</p>"},{"location":"From%20LLM/pyspark-hudi-minio/#what-we-built","title":"\ud83d\udccb What We Built","text":""},{"location":"From%20LLM/pyspark-hudi-minio/#components","title":"Components","text":"<ul> <li>PySpark 3.5.0 (EMR 7.3 version)</li> <li>Hudi 0.14.1 (Table format with ACID transactions)</li> <li>MinIO (S3-compatible object storage)</li> <li>Jupyter Lab (Interactive development)</li> <li>Delta Lake 3.1.0 (Bonus)</li> <li>Iceberg 1.4.3 (Bonus)</li> </ul>"},{"location":"From%20LLM/pyspark-hudi-minio/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Your Local Machine                     \u2502\n\u2502  \u251c\u2500\u2500 workspace/  (synced) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u251c\u2500\u2500 notebooks/  (synced) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502\n\u2502  \u251c\u2500\u2500 scripts/    (synced) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502\n\u2502  \u2514\u2500\u2500 config/     (synced) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2518\n                                      \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  Docker Containers                 \u2502\n                    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n                    \u2502  \u2502  PySpark + Hudi              \u2502  \u2502\n                    \u2502  \u2502  - Jupyter Lab :8888         \u2502  \u2502\n                    \u2502  \u2502  - Spark UI :4040            \u2502  \u2502\n                    \u2502  \u2502  - Java 17 + Python 3.11     \u2502  \u2502\n                    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n                    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n                    \u2502  \u2502  MinIO (S3)                  \u2502  \u2502\n                    \u2502  \u2502  - API :9000                 \u2502  \u2502\n                    \u2502  \u2502  - Console :9001             \u2502  \u2502\n                    \u2502  \u2502  - Buckets: hudi-bucket,     \u2502  \u2502\n                    \u2502  \u2502    delta-bucket, data-lake   \u2502  \u2502\n                    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#complete-setup-instructions","title":"\ud83d\ude80 Complete Setup Instructions","text":""},{"location":"From%20LLM/pyspark-hudi-minio/#step-1-create-project-structure","title":"Step 1: Create Project Structure","text":"<pre><code># Create main directory\nmkdir pyspark-hudi-emr73\ncd pyspark-hudi-emr73\n\n# Create subdirectories for code\nmkdir workspace notebooks scripts config\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#step-2-create-dockerfile","title":"Step 2: Create Dockerfile","text":"<p>Create <code>Dockerfile</code> with this content:</p> <pre><code># Dockerfile - EMR 7.3 Compatible Setup (Ubuntu Base)\nFROM ubuntu:22.04\n\n# Prevent interactive prompts during package installation\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install dependencies and add Python 3.11 repository\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    software-properties-common \\\n    wget \\\n    curl \\\n    procps \\\n    &amp;&amp; add-apt-repository ppa:deadsnakes/ppa -y \\\n    &amp;&amp; apt-get update \\\n    &amp;&amp; apt-get install -y \\\n    openjdk-17-jdk \\\n    python3.11 \\\n    python3.11-distutils \\\n    python3.11-dev \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install pip for Python 3.11\nRUN curl -sS https://bootstrap.pypa.io/get-pip.py | python3.11\n\n# Set Java and Python as default\nENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64\nENV PATH=$JAVA_HOME/bin:$PATH\n\n# Create symbolic links for python\nRUN ln -sf /usr/bin/python3.11 /usr/bin/python3 &amp;&amp; \\\n    ln -sf /usr/bin/python3.11 /usr/bin/python\n\n# EMR 7.3 versions\nENV SPARK_VERSION=3.5.0\nENV HADOOP_VERSION=3.3.6\nENV HUDI_VERSION=0.14.1\nENV DELTA_VERSION=3.1.0\nENV ICEBERG_VERSION=1.4.3\nENV SPARK_HOME=/usr/lib/spark\nENV HADOOP_HOME=/usr/lib/hadoop\nENV PATH=$SPARK_HOME/bin:$HADOOP_HOME/bin:$PATH\nENV PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.9.7-src.zip:$PYTHONPATH\n\n# Download and install Hadoop\nRUN wget -q https://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz \\\n    &amp;&amp; tar -xzf hadoop-${HADOOP_VERSION}.tar.gz -C /usr/lib \\\n    &amp;&amp; mv /usr/lib/hadoop-${HADOOP_VERSION} $HADOOP_HOME \\\n    &amp;&amp; rm hadoop-${HADOOP_VERSION}.tar.gz\n\n# Download and install Spark\nRUN wget -q https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop3.tgz \\\n    &amp;&amp; tar -xzf spark-${SPARK_VERSION}-bin-hadoop3.tgz -C /usr/lib \\\n    &amp;&amp; mv /usr/lib/spark-${SPARK_VERSION}-bin-hadoop3 $SPARK_HOME \\\n    &amp;&amp; rm spark-${SPARK_VERSION}-bin-hadoop3.tgz\n\n# Install PySpark and other Python dependencies (EMR 7.3 compatible versions)\nRUN python3.11 -m pip install --no-cache-dir \\\n    pyspark==3.5.0 \\\n    jupyter \\\n    jupyterlab \\\n    pandas==2.1.4 \\\n    numpy==1.26.3 \\\n    boto3==1.34.34 \\\n    pyarrow==14.0.1\n\n# Download Hudi bundle (EMR 7.3 uses Spark 3.5)\nRUN wget -q https://repo1.maven.org/maven2/org/apache/hudi/hudi-spark3.5-bundle_2.12/${HUDI_VERSION}/hudi-spark3.5-bundle_2.12-${HUDI_VERSION}.jar \\\n    -P $SPARK_HOME/jars/\n\n# Download Delta Lake jars\nRUN wget -q https://repo1.maven.org/maven2/io/delta/delta-spark_2.12/${DELTA_VERSION}/delta-spark_2.12-${DELTA_VERSION}.jar \\\n    -P $SPARK_HOME/jars/ \\\n    &amp;&amp; wget -q https://repo1.maven.org/maven2/io/delta/delta-storage/${DELTA_VERSION}/delta-storage-${DELTA_VERSION}.jar \\\n    -P $SPARK_HOME/jars/\n\n# Download Iceberg jars\nRUN wget -q https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.5_2.12/${ICEBERG_VERSION}/iceberg-spark-runtime-3.5_2.12-${ICEBERG_VERSION}.jar \\\n    -P $SPARK_HOME/jars/\n\n# Download AWS SDK jars for S3 support\nRUN wget -q https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/${HADOOP_VERSION}/hadoop-aws-${HADOOP_VERSION}.jar \\\n    -P $SPARK_HOME/jars/ \\\n    &amp;&amp; wget -q https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar \\\n    -P $SPARK_HOME/jars/\n\nWORKDIR /workspace\n\n# Expose ports\nEXPOSE 8888 4040 18080\n\nCMD [\"bash\"]\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#step-3-create-docker-composeyml","title":"Step 3: Create docker-compose.yml","text":"<p>Create <code>docker-compose.yml</code> with this content:</p> <pre><code>version: '3.8'\n\nservices:\n  # MinIO - S3 Compatible Storage\n  minio:\n    image: minio/minio:latest\n    container_name: minio\n    ports:\n      - \"9000:9000\"      # API port\n      - \"9001:9001\"      # Console port\n    environment:\n      MINIO_ROOT_USER: ROOTNAME\n      MINIO_ROOT_PASSWORD: CHANGEME123\n    volumes:\n      - minio-data:/data\n    command: server /data --console-address \":9001\"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9000/minio/health/live\"]\n      interval: 30s\n      timeout: 20s\n      retries: 3\n\n  # MinIO Client - Create bucket on startup\n  minio-setup:\n    image: minio/mc:latest\n    container_name: minio-setup\n    depends_on:\n      - minio\n    entrypoint: &gt;\n      /bin/sh -c \"\n      sleep 5;\n      /usr/bin/mc alias set myminio http://minio:9000 ROOTNAME CHANGEME123;\n      /usr/bin/mc mb myminio/hudi-bucket --ignore-existing;\n      /usr/bin/mc mb myminio/delta-bucket --ignore-existing;\n      /usr/bin/mc mb myminio/data-lake --ignore-existing;\n      echo 'Buckets created successfully';\n      exit 0;\n      \"\n\n  # PySpark with Hudi\n  pyspark-hudi:\n    build: .\n    container_name: pyspark-hudi-dev\n    depends_on:\n      - minio\n    volumes:\n      - ./workspace:/workspace          # Your code and data\n      - ./notebooks:/notebooks          # Jupyter notebooks\n      - ./scripts:/scripts              # Python scripts\n      - ./config:/config                # Configuration files\n    ports:\n      - \"8888:8888\"  # Jupyter\n      - \"4040:4040\"  # Spark UI\n      - \"18080:18080\" # Spark History Server\n    environment:\n      - JUPYTER_ENABLE_LAB=yes\n      - MINIO_ENDPOINT=http://minio:9000\n      - MINIO_ACCESS_KEY=ROOTNAME\n      - MINIO_SECRET_KEY=CHANGEME123\n    command: jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token='' --NotebookApp.password=''\n\nvolumes:\n  minio-data:\n    driver: local\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#step-4-build-and-start","title":"Step 4: Build and Start","text":"<pre><code># Build the Docker image (takes 5-10 minutes first time)\ndocker-compose build\n\n# Start all services\ndocker-compose up -d\n\n# Verify everything is running\ndocker-compose ps\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#step-5-create-test-script","title":"Step 5: Create Test Script","text":"<p>Create <code>scripts/test_hudi_minio.py</code>:</p> <pre><code>from pyspark.sql import SparkSession\nimport os\n\n# MinIO Configuration\nminio_endpoint = os.getenv(\"MINIO_ENDPOINT\", \"http://minio:9000\")\nminio_access_key = os.getenv(\"MINIO_ACCESS_KEY\", \"ROOTNAME\")\nminio_secret_key = os.getenv(\"MINIO_SECRET_KEY\", \"CHANGEME123\")\n\n# Create Spark session with Hudi and MinIO\nspark = SparkSession.builder \\\n    .appName(\"Hudi-MinIO-EMR-7.3\") \\\n    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.hudi.catalog.HoodieCatalog\") \\\n    .config(\"spark.sql.extensions\", \"org.apache.spark.sql.hudi.HoodieSparkSessionExtension\") \\\n    .config(\"spark.kryo.registrator\", \"org.apache.spark.HoodieSparkKryoRegistrar\") \\\n    .config(\"spark.hadoop.fs.s3a.endpoint\", minio_endpoint) \\\n    .config(\"spark.hadoop.fs.s3a.access.key\", minio_access_key) \\\n    .config(\"spark.hadoop.fs.s3a.secret.key\", minio_secret_key) \\\n    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n    .getOrCreate()\n\nprint(\"\u2705 Spark Version:\", spark.version)\nprint(\"\u2705 MinIO Endpoint:\", minio_endpoint)\n\n# Sample data\ndata = [\n    (1, \"Alice\", 25, \"Engineering\", \"2024-01-01\"),\n    (2, \"Bob\", 30, \"Sales\", \"2024-01-01\"),\n    (3, \"Charlie\", 35, \"Marketing\", \"2024-01-01\")\n]\n\ndf = spark.createDataFrame(data, [\"id\", \"name\", \"age\", \"department\", \"date\"])\nprint(\"\\n\ud83d\udcca Original Data:\")\ndf.show()\n\n# Hudi configuration for MinIO\ntable_name = \"employee_table\"\ns3_path = f\"s3a://hudi-bucket/{table_name}\"\n\nhudi_options = {\n    'hoodie.table.name': table_name,\n    'hoodie.datasource.write.recordkey.field': 'id',\n    'hoodie.datasource.write.partitionpath.field': 'date',\n    'hoodie.datasource.write.table.name': table_name,\n    'hoodie.datasource.write.operation': 'upsert',\n    'hoodie.datasource.write.precombine.field': 'age',\n    'hoodie.datasource.write.hive_style_partitioning': 'true',\n    'hoodie.upsert.shuffle.parallelism': 2,\n    'hoodie.insert.shuffle.parallelism': 2\n}\n\n# Write to Hudi table in MinIO\nprint(f\"\\n\ud83d\udcbe Writing to MinIO: {s3_path}\")\ndf.write.format(\"hudi\") \\\n    .options(**hudi_options) \\\n    .mode(\"overwrite\") \\\n    .save(s3_path)\n\nprint(\"\u2705 Data written successfully!\")\n\n# Read from Hudi table\nprint(f\"\\n\ud83d\udcd6 Reading from MinIO: {s3_path}\")\nhudi_df = spark.read.format(\"hudi\").load(s3_path)\nhudi_df.select(\"id\", \"name\", \"age\", \"department\", \"date\").show()\n\n# Update operation\nupdate_data = [\n    (2, \"Bob Smith\", 31, \"Sales\", \"2024-01-01\"),\n    (4, \"Diana\", 28, \"HR\", \"2024-01-02\")\n]\n\nupdate_df = spark.createDataFrame(update_data, [\"id\", \"name\", \"age\", \"department\", \"date\"])\n\nupdate_df.write.format(\"hudi\") \\\n    .options(**hudi_options) \\\n    .mode(\"append\") \\\n    .save(s3_path)\n\nprint(\"\\n\u2705 Upsert completed!\")\n\n# Read updated data\nupdated_hudi_df = spark.read.format(\"hudi\").load(s3_path)\nupdated_hudi_df.select(\"id\", \"name\", \"age\", \"department\", \"date\") \\\n    .orderBy(\"id\") \\\n    .show()\n\nprint(\"\\n\ud83c\udf89 Test completed successfully!\")\nspark.stop()\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#step-6-run-test","title":"Step 6: Run Test","text":"<pre><code># Run the test script\ndocker exec pyspark-hudi-dev python3 /scripts/test_hudi_minio.py\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#access-points","title":"\ud83c\udf10 Access Points","text":"Service URL Credentials Jupyter Lab http://localhost:8888 No password MinIO Console http://localhost:9001 ROOTNAME / CHANGEME123 Spark UI http://localhost:4040 (when job running)"},{"location":"From%20LLM/pyspark-hudi-minio/#volume-mapping","title":"\ud83d\udcc2 Volume Mapping","text":"<p>Your local files are automatically synced:</p> <pre><code>Local Directory          \u2192  Container Path\n./workspace/            \u2192  /workspace/\n./notebooks/            \u2192  /notebooks/\n./scripts/              \u2192  /scripts/\n./config/               \u2192  /config/\n</code></pre> <p>This means: - Edit code on your local machine with any IDE - Changes are instantly available in the container - No need to rebuild or restart</p>"},{"location":"From%20LLM/pyspark-hudi-minio/#development-workflow","title":"\ud83d\udcbb Development Workflow","text":""},{"location":"From%20LLM/pyspark-hudi-minio/#option-1-jupyter-lab-recommended","title":"Option 1: Jupyter Lab (Recommended)","text":"<pre><code># Open browser\nhttp://localhost:8888\n\n# Create notebook and start coding\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#option-2-python-scripts","title":"Option 2: Python Scripts","text":"<pre><code># Create script locally\nvim scripts/my_job.py\n\n# Run in container\ndocker exec pyspark-hudi-dev python3 /scripts/my_job.py\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#option-3-interactive-shell","title":"Option 3: Interactive Shell","text":"<pre><code># Access container\ndocker exec -it pyspark-hudi-dev bash\n\n# Run PySpark shell\npyspark\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#common-commands","title":"\ud83d\udd27 Common Commands","text":"<pre><code># View logs\ndocker-compose logs -f pyspark-hudi\n\n# Stop services\ndocker-compose down\n\n# Stop and remove all data\ndocker-compose down -v\n\n# Restart services\ndocker-compose restart\n\n# Rebuild after Dockerfile changes\ndocker-compose build --no-cache\ndocker-compose up -d\n\n# Access container shell\ndocker exec -it pyspark-hudi-dev bash\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#emr-73-version-compatibility","title":"\ud83d\udcca EMR 7.3 Version Compatibility","text":"Component Version Match EMR 7.3 Java 17 \u2705 Python 3.11 \u2705 Spark 3.5.0 \u2705 Hadoop 3.3.6 \u2705 Hudi 0.14.1 \u2705 Delta Lake 3.1.0 \u2705 Iceberg 1.4.3 \u2705"},{"location":"From%20LLM/pyspark-hudi-minio/#key-design-decisions","title":"\ud83c\udfaf Key Design Decisions","text":""},{"location":"From%20LLM/pyspark-hudi-minio/#why-ubuntu-base-image","title":"Why Ubuntu Base Image?","text":"<ul> <li>\u2705 More straightforward package management</li> <li>\u2705 Better Python 3.11 support via deadsnakes PPA</li> <li>\u2705 Familiar for most developers</li> <li>\u2705 Reliable pip installation</li> </ul>"},{"location":"From%20LLM/pyspark-hudi-minio/#why-minio","title":"Why MinIO?","text":"<ul> <li>\u2705 S3-compatible API (test locally, deploy to S3)</li> <li>\u2705 Fast local storage</li> <li>\u2705 Web console for debugging</li> <li>\u2705 No AWS credentials needed for development</li> </ul>"},{"location":"From%20LLM/pyspark-hudi-minio/#why-volume-mounting","title":"Why Volume Mounting?","text":"<ul> <li>\u2705 Code persists on your machine</li> <li>\u2705 Use your favorite IDE</li> <li>\u2705 No need to rebuild on code changes</li> <li>\u2705 Easy version control with git</li> </ul>"},{"location":"From%20LLM/pyspark-hudi-minio/#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"From%20LLM/pyspark-hudi-minio/#port-already-in-use","title":"Port Already in Use","text":"<pre><code># Find what's using the port\nlsof -i :8888\n\n# Kill it or change port in docker-compose.yml\n# Change \"8888:8888\" to \"8889:8888\"\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#container-wont-start","title":"Container Won't Start","text":"<pre><code># Check logs\ndocker-compose logs pyspark-hudi\n\n# Ensure Docker has enough resources\n# Docker Desktop \u2192 Settings \u2192 Resources \u2192 RAM: 8GB\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#cant-connect-to-minio","title":"Can't Connect to MinIO","text":"<ul> <li>Inside container: use <code>http://minio:9000</code></li> <li>From host: use <code>http://localhost:9000</code></li> </ul>"},{"location":"From%20LLM/pyspark-hudi-minio/#build-fails","title":"Build Fails","text":"<pre><code># Clean everything\ndocker-compose down -v\ndocker system prune -af\n\n# Rebuild from scratch\ndocker-compose build --no-cache\n</code></pre>"},{"location":"From%20LLM/pyspark-hudi-minio/#next-steps","title":"\ud83d\ude80 Next Steps","text":"<p>Now you can: - \u2705 Develop Hudi pipelines locally - \u2705 Test complex transformations - \u2705 Debug before deploying to EMR - \u2705 Share environment with team (just share Dockerfile + docker-compose.yml) - \u2705 Version control your entire dev environment</p>"},{"location":"From%20LLM/pyspark-hudi-minio/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Hudi Documentation: https://hudi.apache.org/docs/overview/</li> <li>MinIO Documentation: https://min.io/docs/minio/linux/index.html</li> <li>Spark Documentation: https://spark.apache.org/docs/3.5.0/</li> <li>EMR 7.3 Release Notes: https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-730-release.html</li> </ul>"},{"location":"From%20LLM/pyspark-hudi-minio/#summary","title":"\u2728 Summary","text":"<p>You now have a complete local EMR 7.3 environment with: - \u2705 PySpark + Hudi for lakehouse operations - \u2705 MinIO for S3-compatible storage - \u2705 Jupyter Lab for interactive development - \u2705 Volume mounting for seamless code editing - \u2705 No Java/Python version conflicts - \u2705 Production-like testing environment</p> <p>Happy Coding! \ud83c\udf89</p>"},{"location":"Homelab/2%20Laptop%20Homelab/","title":"Homelab High Availability Setup Documentation","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#overview","title":"Overview","text":"<p>2-laptop homelab setup with mixed access (internet + local only), automatic failover for internet services, and data replication.</p> <p>Hardware: - Laptop 1: 8GB RAM (Primary) - Laptop 2: 4GB RAM (Secondary/Failover) - Personal Laptop: Client device</p>"},{"location":"Homelab/2%20Laptop%20Homelab/#architecture","title":"Architecture","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#network-topology","title":"Network Topology","text":"<pre><code>Internet Users\n     \u2193\nCloudflare Tunnel (Immich + Flask Apps Only)\n     \u2193\nLaptop 1 (Primary) \u2190--Auto Failover--\u2192 Laptop 2 (Standby)\n     \u2191                                        \u2191\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Local Network \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              (All Services Available)\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#service-distribution","title":"Service Distribution","text":"Service Laptop 1 (8GB) Laptop 2 (4GB) Access Method Failover Immich Primary Replica Internet (Cloudflare) Auto (30-60s) Flask Apps Primary Replica Internet (Cloudflare) Auto (30-60s) Jellyfin Active Active Local Only Manual Pi-hole - Primary Local Only Manual Portainer Active - Local Only Manual Traefik Active Active Local Only - Homepage Active - Local Only Manual Syncthing Active Active Background -"},{"location":"Homelab/2%20Laptop%20Homelab/#laptop-1-configuration-8gb-ram-primary","title":"Laptop 1 Configuration (8GB RAM - Primary)","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#services-breakdown","title":"Services Breakdown","text":"<p>Internet-Facing (via Cloudflare Tunnel): - Immich (primary instance) - Flask web applications - Cloudflared tunnel \u2192 <code>immich.yourdomain.com</code>, <code>app.yourdomain.com</code></p> <p>Local-Only: - Jellyfin \u2192 <code>http://laptop1.local:8096</code> or <code>http://jellyfin.local</code> - Traefik (local reverse proxy) \u2192 <code>http://laptop1.local</code> - Portainer \u2192 <code>http://laptop1.local:9000</code> - Homepage dashboard \u2192 <code>http://laptop1.local:3000</code></p> <p>Background Services: - Syncthing (data replication to Laptop 2) - Docker runtime</p>"},{"location":"Homelab/2%20Laptop%20Homelab/#folder-structure","title":"Folder Structure","text":"<pre><code>/home/user/\n\u251c\u2500\u2500 docker/\n\u2502   \u251c\u2500\u2500 immich/              # Exposed via Cloudflare\n\u2502   \u2502   \u2514\u2500\u2500 docker-compose.yml\n\u2502   \u251c\u2500\u2500 flask-app/           # Exposed via Cloudflare\n\u2502   \u2502   \u2514\u2500\u2500 docker-compose.yml\n\u2502   \u251c\u2500\u2500 jellyfin/            # Local only\n\u2502   \u2502   \u2514\u2500\u2500 docker-compose.yml\n\u2502   \u251c\u2500\u2500 portainer/           # Local only\n\u2502   \u2502   \u2514\u2500\u2500 docker-compose.yml\n\u2502   \u251c\u2500\u2500 homepage/            # Local only\n\u2502   \u2502   \u2514\u2500\u2500 docker-compose.yml\n\u2502   \u2514\u2500\u2500 traefik/             # Local reverse proxy\n\u2502       \u2514\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 data/                    # Synced via Syncthing\n\u2502   \u251c\u2500\u2500 immich/\n\u2502   \u2502   \u251c\u2500\u2500 photos/\n\u2502   \u2502   \u2514\u2500\u2500 database/\n\u2502   \u251c\u2500\u2500 jellyfin/\n\u2502   \u2502   \u2514\u2500\u2500 media/\n\u2502   \u2514\u2500\u2500 app-data/\n\u2514\u2500\u2500 .cloudflared/\n    \u251c\u2500\u2500 config.yml\n    \u2514\u2500\u2500 &lt;tunnel-uuid&gt;.json\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#cloudflared-configuration","title":"Cloudflared Configuration","text":"<p>File: <code>~/.cloudflared/config.yml</code></p> <pre><code>tunnel: &lt;TUNNEL_1_UUID&gt;\ncredentials-file: /home/user/.cloudflared/&lt;TUNNEL_1_UUID&gt;.json\n\ningress:\n  # Immich - exposed to internet\n  - hostname: immich.yourdomain.com\n    service: http://localhost:2283\n\n  # Flask app - exposed to internet\n  - hostname: app.yourdomain.com\n    service: http://localhost:5000\n\n  # API endpoint\n  - hostname: api.yourdomain.com\n    service: http://localhost:5001\n\n  # Catch-all (required)\n  - service: http_status:404\n</code></pre> <p>Start cloudflared: <pre><code># Install as service\nsudo cloudflared service install\nsudo systemctl enable cloudflared\nsudo systemctl start cloudflared\n</code></pre></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#laptop-2-configuration-4gb-ram-secondary","title":"Laptop 2 Configuration (4GB RAM - Secondary)","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#services-breakdown_1","title":"Services Breakdown","text":"<p>Internet-Facing (standby - inactive by default): - Immich (replica instance) - Flask apps (replica instances) - Cloudflared tunnel (stopped, starts on failover)</p> <p>Local-Only: - Jellyfin \u2192 <code>http://laptop2.local:8096</code> or <code>http://jellyfin2.local</code> - Traefik (local reverse proxy) - Pi-hole (primary DNS) \u2192 <code>http://laptop2.local:8080</code> or <code>http://pihole.local</code></p> <p>Background Services: - Syncthing (receives data from Laptop 1) - Auto-failover monitoring script</p>"},{"location":"Homelab/2%20Laptop%20Homelab/#folder-structure_1","title":"Folder Structure","text":"<pre><code>/home/user/\n\u251c\u2500\u2500 docker/\n\u2502   \u251c\u2500\u2500 immich/              # Replica (same config)\n\u2502   \u251c\u2500\u2500 flask-app/           # Replica (same config)\n\u2502   \u251c\u2500\u2500 jellyfin/            # Local only\n\u2502   \u251c\u2500\u2500 pihole/              # Local DNS\n\u2502   \u2514\u2500\u2500 traefik/\n\u251c\u2500\u2500 data/                    # Synced from Laptop 1\n\u2502   \u251c\u2500\u2500 immich/\n\u2502   \u251c\u2500\u2500 jellyfin/\n\u2502   \u2514\u2500\u2500 app-data/\n\u251c\u2500\u2500 .cloudflared/\n\u2502   \u251c\u2500\u2500 config.yml           # Same as Laptop 1\n\u2502   \u2514\u2500\u2500 &lt;tunnel-uuid&gt;.json\n\u2514\u2500\u2500 scripts/\n    \u2514\u2500\u2500 auto-failover.sh     # Monitoring script\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#cloudflared-configuration_1","title":"Cloudflared Configuration","text":"<p>File: <code>~/.cloudflared/config.yml</code></p> <pre><code>tunnel: &lt;TUNNEL_2_UUID&gt;\ncredentials-file: /home/user/.cloudflared/&lt;TUNNEL_2_UUID&gt;.json\n\n# Same ingress config as Laptop 1\ningress:\n  - hostname: immich.yourdomain.com\n    service: http://localhost:2283\n\n  - hostname: app.yourdomain.com\n    service: http://localhost:5000\n\n  - hostname: api.yourdomain.com\n    service: http://localhost:5001\n\n  - service: http_status:404\n</code></pre> <p>Setup (but don't start by default): <pre><code># Install but disable service\nsudo cloudflared service install\nsudo systemctl disable cloudflared\nsudo systemctl stop cloudflared\n\n# Will be started by auto-failover script when needed\n</code></pre></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#data-replication-with-syncthing","title":"Data Replication with Syncthing","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#setup-on-both-laptops","title":"Setup on Both Laptops","text":"<p>Install Syncthing: <pre><code># Ubuntu/Debian\nsudo apt install syncthing\n\n# Enable service\nsudo systemctl enable syncthing@$USER\nsudo systemctl start syncthing@$USER\n</code></pre></p> <p>Access Web UI: - Laptop 1: <code>http://laptop1.local:8384</code> - Laptop 2: <code>http://laptop2.local:8384</code></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#shared-folders-configuration","title":"Shared Folders Configuration","text":"<p>Create these shared folders (bidirectional sync):</p> <ol> <li>Immich Photos</li> <li>Path: <code>/home/user/data/immich/photos</code></li> <li>Sync Type: Send &amp; Receive</li> <li> <p>Version Control: Staggered (30 days)</p> </li> <li> <p>Jellyfin Media</p> </li> <li>Path: <code>/home/user/data/jellyfin/media</code></li> <li>Sync Type: Send &amp; Receive</li> <li> <p>Version Control: Staggered (30 days)</p> </li> <li> <p>Application Data</p> </li> <li>Path: <code>/home/user/data/app-data</code></li> <li>Sync Type: Send &amp; Receive</li> <li>Ignore Patterns: <code>*.log</code>, <code>*.tmp</code>, <code>cache/</code></li> </ol>"},{"location":"Homelab/2%20Laptop%20Homelab/#connect-laptops","title":"Connect Laptops","text":"<ol> <li>On Laptop 1: Add Remote Device (use Laptop 2's Device ID)</li> <li>On Laptop 2: Accept connection request</li> <li>Share folders between devices</li> </ol>"},{"location":"Homelab/2%20Laptop%20Homelab/#auto-failover-system","title":"Auto-Failover System","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#monitoring-script","title":"Monitoring Script","text":"<p>File: <code>/home/user/scripts/auto-failover.sh</code></p> <pre><code>#!/bin/bash\n# Auto-failover for internet-facing services only\n# Run this on Laptop 2\n\n# Configuration\nLAPTOP1_IP=\"192.168.1.101\"\nCF_ZONE_ID=\"your_cloudflare_zone_id\"\nCF_RECORD_ID_IMMICH=\"immich_record_id\"\nCF_RECORD_ID_APP=\"app_record_id\"\nCF_API_TOKEN=\"your_api_token\"\nTUNNEL1_CNAME=\"tunnel-1-uuid.cfargotunnel.com\"\nTUNNEL2_CNAME=\"tunnel-2-uuid.cfargotunnel.com\"\n\nFAILOVER_TRIGGERED=false\nLOG_FILE=\"/var/log/homelab-failover.log\"\n\nlog() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$LOG_FILE\"\n}\n\n# Health check functions\ncheck_immich() {\n    curl -sf --max-time 5 \"http://${LAPTOP1_IP}:2283/api/server-info\" &gt; /dev/null 2&gt;&amp;1\n    return $?\n}\n\ncheck_flask() {\n    curl -sf --max-time 5 \"http://${LAPTOP1_IP}:5000/health\" &gt; /dev/null 2&gt;&amp;1\n    return $?\n}\n\nupdate_cf_dns() {\n    local record_id=$1\n    local target_cname=$2\n\n    curl -X PUT \"https://api.cloudflare.com/client/v4/zones/$CF_ZONE_ID/dns_records/$record_id\" \\\n        -H \"Authorization: Bearer $CF_API_TOKEN\" \\\n        -H \"Content-Type: application/json\" \\\n        --data \"{\\\"type\\\":\\\"CNAME\\\",\\\"content\\\":\\\"$target_cname\\\",\\\"proxied\\\":true}\" \\\n        -s &gt; /dev/null\n}\n\n# Main monitoring loop\nlog \"Starting auto-failover monitor\"\n\nwhile true; do\n    if ! check_immich || ! check_flask; then\n        if [ \"$FAILOVER_TRIGGERED\" = false ]; then\n            log \"ALERT: Laptop 1 services down. Initiating failover to Laptop 2...\"\n\n            # Start cloudflared on Laptop 2\n            sudo systemctl start cloudflared\n            sleep 5\n\n            # Update DNS records to Laptop 2's tunnel\n            update_cf_dns \"$CF_RECORD_ID_IMMICH\" \"$TUNNEL2_CNAME\"\n            update_cf_dns \"$CF_RECORD_ID_APP\" \"$TUNNEL2_CNAME\"\n\n            FAILOVER_TRIGGERED=true\n            log \"SUCCESS: Failover to Laptop 2 completed\"\n\n            # Send notification (optional)\n            # curl -X POST \"https://ntfy.sh/yourtopic\" -d \"Homelab failed over to Laptop 2\"\n        fi\n    else\n        # Laptop 1 is healthy\n        if [ \"$FAILOVER_TRIGGERED\" = true ]; then\n            log \"INFO: Laptop 1 recovered. Initiating failback...\"\n\n            # Update DNS back to Laptop 1\n            update_cf_dns \"$CF_RECORD_ID_IMMICH\" \"$TUNNEL1_CNAME\"\n            update_cf_dns \"$CF_RECORD_ID_APP\" \"$TUNNEL1_CNAME\"\n\n            sleep 10\n\n            # Stop cloudflared on Laptop 2\n            sudo systemctl stop cloudflared\n\n            FAILOVER_TRIGGERED=false\n            log \"SUCCESS: Failback to Laptop 1 completed\"\n\n            # Send notification (optional)\n            # curl -X POST \"https://ntfy.sh/yourtopic\" -d \"Homelab failed back to Laptop 1\"\n        fi\n    fi\n\n    sleep 30  # Check every 30 seconds\ndone\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#install-as-systemd-service","title":"Install as Systemd Service","text":"<p>File: <code>/etc/systemd/system/homelab-failover.service</code></p> <pre><code>[Unit]\nDescription=Homelab Auto-Failover Monitor\nAfter=network-online.target\nWants=network-online.target\n\n[Service]\nType=simple\nUser=youruser\nExecStart=/bin/bash /home/youruser/scripts/auto-failover.sh\nRestart=always\nRestartSec=10\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Enable and start: <pre><code>sudo chmod +x /home/user/scripts/auto-failover.sh\nsudo systemctl daemon-reload\nsudo systemctl enable homelab-failover\nsudo systemctl start homelab-failover\n\n# Check status\nsudo systemctl status homelab-failover\n\n# View logs\nsudo journalctl -u homelab-failover -f\n</code></pre></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#local-dns-with-pi-hole","title":"Local DNS with Pi-hole","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#pi-hole-setup-laptop-2","title":"Pi-hole Setup (Laptop 2)","text":"<p>Install Pi-hole: <pre><code>curl -sSL https://install.pi-hole.net | bash\n</code></pre></p> <p>Configuration: - Interface: Listen on all interfaces - Upstream DNS: Cloudflare (1.1.1.1) - Admin Web Port: 8080</p>"},{"location":"Homelab/2%20Laptop%20Homelab/#local-dns-records","title":"Local DNS Records","text":"<p>File: <code>/etc/pihole/custom.list</code></p> <pre><code># Laptop 1 services\n192.168.1.101 laptop1.local\n192.168.1.101 jellyfin.local\n192.168.1.101 portainer.local\n192.168.1.101 home.local\n192.168.1.101 immich.local\n\n# Laptop 2 services\n192.168.1.102 laptop2.local\n192.168.1.102 jellyfin2.local\n192.168.1.102 pihole.local\n</code></pre> <p>Apply changes: <pre><code>pihole restartdns\n</code></pre></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#configure-clients","title":"Configure Clients","text":"<p>Option 1: Router-level (Recommended) - Set DHCP DNS server to Laptop 2 IP: <code>192.168.1.102</code> - All devices automatically use Pi-hole</p> <p>Option 2: Per-device - Manually set DNS to <code>192.168.1.102</code></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#docker-compose-examples","title":"Docker Compose Examples","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#traefik-local-reverse-proxy","title":"Traefik (Local Reverse Proxy)","text":"<p>File: <code>~/docker/traefik/docker-compose.yml</code></p> <pre><code>version: '3.8'\n\nservices:\n  traefik:\n    image: traefik:v2.10\n    container_name: traefik\n    restart: unless-stopped\n    ports:\n      - \"80:80\"\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n    command:\n      - --providers.docker=true\n      - --providers.docker.exposedbydefault=false\n      - --entrypoints.web.address=:80\n    networks:\n      - homelab\n\nnetworks:\n  homelab:\n    name: homelab\n    driver: bridge\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#jellyfin-local-only","title":"Jellyfin (Local Only)","text":"<p>File: <code>~/docker/jellyfin/docker-compose.yml</code></p> <pre><code>version: '3.8'\n\nservices:\n  jellyfin:\n    image: jellyfin/jellyfin:latest\n    container_name: jellyfin\n    restart: unless-stopped\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=Asia/Jakarta\n    volumes:\n      - ./config:/config\n      - /home/user/data/jellyfin/media:/media\n    ports:\n      - \"8096:8096\"\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.jellyfin.rule=Host(`jellyfin.local`)\"\n      - \"traefik.http.services.jellyfin.loadbalancer.server.port=8096\"\n    networks:\n      - homelab\n\nnetworks:\n  homelab:\n    external: true\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#immich-internet-local","title":"Immich (Internet + Local)","text":"<p>File: <code>~/docker/immich/docker-compose.yml</code></p> <pre><code>version: '3.8'\n\nservices:\n  immich-server:\n    image: ghcr.io/immich-app/immich-server:release\n    container_name: immich_server\n    restart: unless-stopped\n    command: ['start.sh', 'immich']\n    volumes:\n      - /home/user/data/immich/photos:/usr/src/app/upload\n      - /etc/localtime:/etc/localtime:ro\n    environment:\n      - DB_HOSTNAME=immich_postgres\n      - DB_USERNAME=postgres\n      - DB_PASSWORD=postgres\n      - DB_DATABASE_NAME=immich\n      - REDIS_HOSTNAME=immich_redis\n    ports:\n      - \"2283:3001\"\n    depends_on:\n      - immich_redis\n      - immich_postgres\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.immich.rule=Host(`immich.local`)\"\n      - \"traefik.http.services.immich.loadbalancer.server.port=3001\"\n    networks:\n      - homelab\n\n  immich_redis:\n    image: redis:6.2-alpine\n    container_name: immich_redis\n    restart: unless-stopped\n    networks:\n      - homelab\n\n  immich_postgres:\n    image: tensorchord/pgvecto-rs:pg14-v0.2.0\n    container_name: immich_postgres\n    restart: unless-stopped\n    environment:\n      POSTGRES_PASSWORD: postgres\n      POSTGRES_USER: postgres\n      POSTGRES_DB: immich\n    volumes:\n      - ./postgres:/var/lib/postgresql/data\n    networks:\n      - homelab\n\nnetworks:\n  homelab:\n    external: true\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#access-methods","title":"Access Methods","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#internet-access-from-anywhere","title":"Internet Access (From Anywhere)","text":"Service URL Notes Immich <code>https://immich.yourdomain.com</code> Auto-failover enabled Flask App <code>https://app.yourdomain.com</code> Auto-failover enabled API <code>https://api.yourdomain.com</code> Auto-failover enabled"},{"location":"Homelab/2%20Laptop%20Homelab/#local-access-home-network-only","title":"Local Access (Home Network Only)","text":"Service Primary URL Backup URL Jellyfin <code>http://jellyfin.local</code> <code>http://jellyfin2.local</code> Immich <code>http://immich.local</code> <code>http://laptop2.local:2283</code> Portainer <code>http://portainer.local</code> <code>http://laptop1.local:9000</code> Pi-hole <code>http://pihole.local/admin</code> <code>http://laptop2.local:8080/admin</code> Homepage <code>http://home.local</code> <code>http://laptop1.local:3000</code>"},{"location":"Homelab/2%20Laptop%20Homelab/#personal-laptop-workflow","title":"Personal Laptop Workflow","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#immich-photo-sync","title":"Immich Photo Sync","text":"<p>Option 1: Immich CLI (Recommended) <pre><code># Install\nnpm install -g @immich/cli\n\n# Configure\nimmich login https://immich.yourdomain.com\n\n# Upload photos\nimmich upload ~/Pictures/\n</code></pre></p> <p>Option 2: zsync (Your current method) <pre><code># Sync to Laptop 1\nzsync ~/Photos/ user@laptop1.local:/home/user/data/immich/photos/\n\n# Syncthing will automatically replicate to Laptop 2\n</code></pre></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#jellyfin-access","title":"Jellyfin Access","text":"<p>When at home: <pre><code># Open browser\nfirefox http://jellyfin.local\n</code></pre></p> <p>Not accessible from internet (by design - security &amp; bandwidth)</p>"},{"location":"Homelab/2%20Laptop%20Homelab/#maintenance-tasks","title":"Maintenance Tasks","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#daily","title":"Daily","text":"<ul> <li>Monitor Syncthing sync status</li> <li>Check failover script logs: <code>journalctl -u homelab-failover --since today</code></li> </ul>"},{"location":"Homelab/2%20Laptop%20Homelab/#weekly","title":"Weekly","text":"<ul> <li>Check Docker container health: <code>docker ps -a</code></li> <li>Review Cloudflare tunnel status</li> <li>Verify backup completion in Syncthing</li> </ul>"},{"location":"Homelab/2%20Laptop%20Homelab/#monthly","title":"Monthly","text":"<ul> <li>Update Docker images: <code>docker-compose pull &amp;&amp; docker-compose up -d</code></li> <li>Test failover by stopping Laptop 1 services</li> <li>Clean old Syncthing versions: Check <code>.stversions</code> folders</li> <li>Update Pi-hole: <code>pihole -up</code></li> </ul>"},{"location":"Homelab/2%20Laptop%20Homelab/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#failover-not-working","title":"Failover Not Working","text":"<p>Check monitoring script: <pre><code>sudo systemctl status homelab-failover\nsudo journalctl -u homelab-failover -n 50\n</code></pre></p> <p>Test health endpoints manually: <pre><code>curl http://192.168.1.101:2283/api/server-info\ncurl http://192.168.1.101:5000/health\n</code></pre></p> <p>Check Cloudflare tunnel on Laptop 2: <pre><code>sudo systemctl status cloudflared\nsudo cloudflared tunnel list\n</code></pre></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#syncthing-not-syncing","title":"Syncthing Not Syncing","text":"<p>Check Syncthing status: <pre><code># Web UI\nhttp://laptop1.local:8384\nhttp://laptop2.local:8384\n\n# Check service\nsudo systemctl status syncthing@$USER\n\n# Check logs\njournalctl -u syncthing@$USER -f\n</code></pre></p> <p>Common issues: - Firewall blocking port 22000 - Different folder IDs between devices - Insufficient disk space</p>"},{"location":"Homelab/2%20Laptop%20Homelab/#local-dns-not-resolving","title":"Local DNS Not Resolving","text":"<p>Check Pi-hole: <pre><code># Status\npihole status\n\n# Restart DNS\npihole restartdns\n\n# Check custom DNS\ncat /etc/pihole/custom.list\n</code></pre></p> <p>Verify client DNS settings: <pre><code># Linux/Mac\ncat /etc/resolv.conf\n\n# Should show: nameserver 192.168.1.102\n</code></pre></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#jellyfin-performance-issues","title":"Jellyfin Performance Issues","text":"<p>Check transcoding: - Disable transcoding for local network - Settings \u2192 Playback \u2192 \"Direct Play\" preferred</p> <p>Check media sync: <pre><code># Verify Syncthing completed\ndu -sh /home/user/data/jellyfin/media\n</code></pre></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#security-considerations","title":"Security Considerations","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#internet-facing-services","title":"Internet-Facing Services","text":"<ul> <li>\u2705 Only Immich and Flask apps exposed</li> <li>\u2705 Cloudflare proxy provides DDoS protection</li> <li>\u2705 HTTPS enforced via Cloudflare</li> <li>\u26a0\ufe0f Enable Immich authentication (password required)</li> <li>\u26a0\ufe0f Enable Flask app authentication if needed</li> </ul>"},{"location":"Homelab/2%20Laptop%20Homelab/#local-services","title":"Local Services","text":"<ul> <li>\u2705 Jellyfin not exposed to internet (bandwidth + security)</li> <li>\u2705 Pi-hole admin interface password-protected</li> <li>\u2705 Portainer requires authentication</li> <li>\u26a0\ufe0f Consider VPN (Tailscale/WireGuard) for remote admin access</li> </ul>"},{"location":"Homelab/2%20Laptop%20Homelab/#network-security","title":"Network Security","text":"<pre><code># Firewall rules (UFW example)\nsudo ufw default deny incoming\nsudo ufw default allow outgoing\nsudo ufw allow from 192.168.1.0/24  # Local network\nsudo ufw enable\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#backup-strategy","title":"Backup Strategy","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#what-to-backup","title":"What to Backup","text":"<ol> <li>Critical Data (Daily via Syncthing):</li> <li>Immich photos (already replicated)</li> <li>Jellyfin media (already replicated)</li> <li> <p>Application databases</p> </li> <li> <p>Configuration Files (Weekly):</p> </li> <li>Docker compose files</li> <li>Cloudflared configs</li> <li>Scripts (auto-failover.sh)</li> <li> <p>Pi-hole custom DNS</p> </li> <li> <p>External Backup (Monthly): <pre><code># Backup to external drive\nrsync -av /home/user/data/ /mnt/external/homelab-backup/\n</code></pre></p> </li> </ol>"},{"location":"Homelab/2%20Laptop%20Homelab/#automated-backup-script","title":"Automated Backup Script","text":"<pre><code>#!/bin/bash\n# backup.sh - Run weekly via cron\n\nBACKUP_DIR=\"/mnt/external/homelab-backup\"\nDATE=$(date +%Y%m%d)\n\n# Backup configs\ntar -czf \"$BACKUP_DIR/configs-$DATE.tar.gz\" \\\n    ~/docker/ \\\n    ~/.cloudflared/ \\\n    ~/scripts/ \\\n    /etc/pihole/custom.list\n\n# Keep only last 4 backups\ncd \"$BACKUP_DIR\"\nls -t configs-*.tar.gz | tail -n +5 | xargs rm -f\n</code></pre> <p>Setup cron: <pre><code>crontab -e\n\n# Add line:\n0 2 * * 0 /home/user/scripts/backup.sh\n</code></pre></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#quick-reference-commands","title":"Quick Reference Commands","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#docker-management","title":"Docker Management","text":"<pre><code># View all containers\ndocker ps -a\n\n# Restart all services\ncd ~/docker/immich &amp;&amp; docker-compose restart\n\n# View logs\ndocker logs -f immich_server\n\n# Update images\ndocker-compose pull &amp;&amp; docker-compose up -d\n\n# Clean up\ndocker system prune -a\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#service-management","title":"Service Management","text":"<pre><code># Cloudflare tunnel\nsudo systemctl status cloudflared\nsudo systemctl restart cloudflared\n\n# Failover monitor\nsudo systemctl status homelab-failover\nsudo journalctl -u homelab-failover -f\n\n# Syncthing\nsudo systemctl status syncthing@$USER\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#network-diagnostics","title":"Network Diagnostics","text":"<pre><code># Test local DNS\nnslookup jellyfin.local 192.168.1.102\n\n# Test Cloudflare tunnel\ncurl -I https://immich.yourdomain.com\n\n# Check ports\nsudo netstat -tulpn | grep LISTEN\n\n# Test failover manually\nsudo systemctl stop docker  # On Laptop 1\n# Wait 30-60 seconds, check if Laptop 2 takes over\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#cloudflare-configuration","title":"Cloudflare Configuration","text":""},{"location":"Homelab/2%20Laptop%20Homelab/#create-tunnels","title":"Create Tunnels","text":"<p>Laptop 1: <pre><code>cloudflared tunnel create homelab-1\ncloudflared tunnel route dns homelab-1 immich.yourdomain.com\ncloudflared tunnel route dns homelab-1 app.yourdomain.com\n</code></pre></p> <p>Laptop 2: <pre><code>cloudflared tunnel create homelab-2\ncloudflared tunnel route dns homelab-2 immich.yourdomain.com\ncloudflared tunnel route dns homelab-2 app.yourdomain.com\n</code></pre></p>"},{"location":"Homelab/2%20Laptop%20Homelab/#get-api-token","title":"Get API Token","text":"<ol> <li>Go to Cloudflare Dashboard</li> <li>My Profile \u2192 API Tokens \u2192 Create Token</li> <li>Edit zone DNS template</li> <li>Copy token for auto-failover script</li> </ol>"},{"location":"Homelab/2%20Laptop%20Homelab/#get-zone-and-record-ids","title":"Get Zone and Record IDs","text":"<pre><code># Get Zone ID\ncurl -X GET \"https://api.cloudflare.com/client/v4/zones\" \\\n  -H \"Authorization: Bearer YOUR_API_TOKEN\" \\\n  | jq -r '.result[] | select(.name==\"yourdomain.com\") | .id'\n\n# Get DNS Record IDs\ncurl -X GET \"https://api.cloudflare.com/client/v4/zones/ZONE_ID/dns_records\" \\\n  -H \"Authorization: Bearer YOUR_API_TOKEN\" \\\n  | jq -r '.result[] | select(.name==\"immich.yourdomain.com\") | .id'\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#appendix-network-diagram","title":"Appendix: Network Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Internet                              \u2502\n\u2502                            \u2502                                 \u2502\n\u2502                   Cloudflare Edge                            \u2502\n\u2502                            \u2502                                 \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502              \u2502                            \u2502                  \u2502\n\u2502         Tunnel 1 (Active)          Tunnel 2 (Standby)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502                            \u2502\n               \u2502     Home Network (LAN)     \u2502\n               \u2502                            \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   Laptop 1 (8GB)   \u2502       \u2502   Laptop 2 (4GB)   \u2502\n    \u2502    192.168.1.101   \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u25ba\u2502    192.168.1.102   \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524       \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 Internet Services: \u2502       \u2502 Internet Services: \u2502\n    \u2502 \u2022 Immich           \u2502       \u2502 \u2022 Immich (replica) \u2502\n    \u2502 \u2022 Flask Apps       \u2502       \u2502 \u2022 Flask (replica)  \u2502\n    \u2502                    \u2502       \u2502                    \u2502\n    \u2502 Local Services:    \u2502       \u2502 Local Services:    \u2502\n    \u2502 \u2022 Jellyfin         \u2502       \u2502 \u2022 Jellyfin         \u2502\n    \u2502 \u2022 Portainer        \u2502       \u2502 \u2022 Pi-hole          \u2502\n    \u2502 \u2022 Homepage         \u2502       \u2502 \u2022 Failover Script  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                             \u2502\n             \u2502      Syncthing Sync         \u2502\n             \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\n             \u2502                             \u2502\n             \u2502                             \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502            Other Devices (Phones, PC)           \u2502\n    \u2502  \u2022 Access via Pi-hole DNS                       \u2502\n    \u2502  \u2022 Local: http://jellyfin.local                 \u2502\n    \u2502  \u2022 Remote: https://immich.yourdomain.com        \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"Homelab/2%20Laptop%20Homelab/#document-information","title":"Document Information","text":"<ul> <li>Created: 2025-10-20</li> <li>Last Updated: 2025-10-20</li> <li>Version: 1.0</li> <li>Author: Homelab Admin</li> <li>Status: Active Configuration</li> </ul>"},{"location":"Homelab/2%20Laptop%20Homelab/#change-log","title":"Change Log","text":"Date Version Changes 2025-10-20 1.0 Initial documentation"},{"location":"Homelab/2%20Laptop%20Homelab/#additional-resources","title":"Additional Resources","text":"<ul> <li>Cloudflare Tunnel Docs: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/</li> <li>Docker Compose Reference: https://docs.docker.com/compose/</li> <li>Syncthing Documentation: https://docs.syncthing.net/</li> <li>Pi-hole Documentation: https://docs.pi-hole.net/</li> <li>Immich Documentation: https://immich.app/docs/overview/introduction</li> <li>Jellyfin Documentation: https://jellyfin.org/docs/</li> </ul>"},{"location":"Homelab/2%20Laptop%20Homelab/#notes","title":"Notes","text":"<ul> <li>Always test failover in a controlled manner before relying on it</li> <li>Keep this documentation updated when making infrastructure changes</li> <li>Regularly review logs for any anomalies</li> <li>Consider adding monitoring notifications (ntfy.sh, Telegram, etc.)</li> <li>Document any custom modifications to this setup</li> </ul>"},{"location":"Homelab/k3s_gcp/","title":"K3s on GCP - Complete Setup Guide","text":""},{"location":"Homelab/k3s_gcp/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Cost Overview</li> <li>Single Node Setup (FREE)</li> <li>3-Node Cluster Setup</li> <li>Flask Application Example</li> <li>Deployment Without Helm</li> <li>Useful Commands</li> </ol>"},{"location":"Homelab/k3s_gcp/#cost-overview","title":"Cost Overview","text":""},{"location":"Homelab/k3s_gcp/#gcp-free-tier","title":"GCP Free Tier","text":"<ul> <li>1 e2-micro VM instance - FREE forever (US regions)</li> <li>30 GB standard persistent disk - FREE</li> <li>1 GB network egress - FREE (North America)</li> </ul>"},{"location":"Homelab/k3s_gcp/#cost-estimate-for-3-node-cluster","title":"Cost Estimate for 3-Node Cluster","text":"Component Quantity Monthly Cost e2-micro #1 (server) 1 $0 (free tier) e2-micro #2 (agent) 1 ~$7-8 e2-micro #3 (agent) 1 ~$7-8 Standard disk (60GB) 60GB ~$1-2 TOTAL ~$15-18/month"},{"location":"Homelab/k3s_gcp/#recommendation","title":"Recommendation","text":"<p>Use single node for learning - it's 100% FREE and covers 90% of learning needs!</p>"},{"location":"Homelab/k3s_gcp/#single-node-setup-free","title":"Single Node Setup (FREE)","text":""},{"location":"Homelab/k3s_gcp/#1-create-vm-instance","title":"1. Create VM Instance","text":"<pre><code>gcloud compute instances create k3s-free \\\n  --zone=us-west1-b \\\n  --machine-type=e2-micro \\\n  --image-family=ubuntu-2204-lts \\\n  --image-project=ubuntu-os-cloud \\\n  --boot-disk-size=30GB \\\n  --boot-disk-type=pd-standard \\\n  --tags=k3s\n</code></pre>"},{"location":"Homelab/k3s_gcp/#2-configure-firewall","title":"2. Configure Firewall","text":"<pre><code># K3s API Server\ngcloud compute firewall-rules create k3s-api \\\n  --allow=tcp:6443 \\\n  --source-ranges=0.0.0.0/0 \\\n  --target-tags=k3s\n\n# HTTP/HTTPS for applications\ngcloud compute firewall-rules create k3s-http \\\n  --allow=tcp:80,tcp:443 \\\n  --source-ranges=0.0.0.0/0 \\\n  --target-tags=k3s\n</code></pre>"},{"location":"Homelab/k3s_gcp/#3-install-k3s","title":"3. Install K3s","text":"<pre><code># SSH into the VM\ngcloud compute ssh k3s-free --zone=us-west1-b\n\n# Install K3s\ncurl -sfL https://get.k3s.io | sh -s - --write-kubeconfig-mode=644\n\n# Verify installation\nsudo kubectl get nodes\n</code></pre>"},{"location":"Homelab/k3s_gcp/#4-setup-local-access","title":"4. Setup Local Access","text":"<pre><code># Copy kubeconfig from server\ngcloud compute scp k3s-free:/etc/rancher/k3s/k3s.yaml ~/.kube/k3s-free --zone=us-west1-b\n\n# Get server external IP\nEXTERNAL_IP=$(gcloud compute instances describe k3s-free \\\n  --zone=us-west1-b \\\n  --format='get(networkInterfaces[0].accessConfigs[0].natIP)')\n\n# Update kubeconfig with external IP\nsed -i \"s/127.0.0.1/$EXTERNAL_IP/g\" ~/.kube/k3s-free\n\n# Use the config\nexport KUBECONFIG=~/.kube/k3s-free\nkubectl get nodes\n</code></pre>"},{"location":"Homelab/k3s_gcp/#cost-saving","title":"Cost Saving","text":"<pre><code># Stop instance when not using\ngcloud compute instances stop k3s-free --zone=us-west1-b\n\n# Start when needed\ngcloud compute instances start k3s-free --zone=us-west1-b\n</code></pre>"},{"location":"Homelab/k3s_gcp/#3-node-cluster-setup","title":"3-Node Cluster Setup","text":""},{"location":"Homelab/k3s_gcp/#1-create-vms","title":"1. Create VMs","text":"<pre><code># Server node\ngcloud compute instances create k3s-server \\\n  --zone=us-central1-a \\\n  --machine-type=e2-medium \\\n  --image-family=ubuntu-2204-lts \\\n  --image-project=ubuntu-os-cloud \\\n  --boot-disk-size=20GB \\\n  --tags=k3s-server\n\n# Agent nodes\nfor i in 1 2; do\n  gcloud compute instances create k3s-agent-$i \\\n    --zone=us-central1-a \\\n    --machine-type=e2-medium \\\n    --image-family=ubuntu-2204-lts \\\n    --image-project=ubuntu-os-cloud \\\n    --boot-disk-size=20GB \\\n    --tags=k3s-agent\ndone\n</code></pre>"},{"location":"Homelab/k3s_gcp/#2-configure-firewall_1","title":"2. Configure Firewall","text":"<pre><code># K3s API server\ngcloud compute firewall-rules create k3s-api \\\n  --allow=tcp:6443 \\\n  --source-ranges=0.0.0.0/0 \\\n  --target-tags=k3s-server\n\n# Internal cluster communication\ngcloud compute firewall-rules create k3s-internal \\\n  --allow=tcp:0-65535,udp:0-65535,icmp \\\n  --source-tags=k3s-server,k3s-agent \\\n  --target-tags=k3s-server,k3s-agent\n</code></pre>"},{"location":"Homelab/k3s_gcp/#3-install-k3s-server","title":"3. Install K3s Server","text":"<pre><code># SSH into server\ngcloud compute ssh k3s-server --zone=us-central1-a\n\n# Install K3s\ncurl -sfL https://get.k3s.io | sh -s - server \\\n  --write-kubeconfig-mode=644 \\\n  --disable=traefik \\\n  --node-external-ip=$(curl -s ifconfig.me)\n\n# Get node token\nsudo cat /var/lib/rancher/k3s/server/node-token\n\n# Get server internal IP\nhostname -I | awk '{print $1}'\n</code></pre>"},{"location":"Homelab/k3s_gcp/#4-join-agent-nodes","title":"4. Join Agent Nodes","text":"<pre><code># SSH into each agent\ngcloud compute ssh k3s-agent-1 --zone=us-central1-a\n\n# Join cluster (replace with your values)\ncurl -sfL https://get.k3s.io | K3S_URL=https://&lt;SERVER_INTERNAL_IP&gt;:6443 \\\n  K3S_TOKEN=&lt;NODE_TOKEN&gt; sh -\n\n# Repeat for k3s-agent-2\n</code></pre>"},{"location":"Homelab/k3s_gcp/#5-verify-cluster","title":"5. Verify Cluster","text":"<pre><code># On server node\nsudo kubectl get nodes\n</code></pre>"},{"location":"Homelab/k3s_gcp/#flask-application-example","title":"Flask Application Example","text":""},{"location":"Homelab/k3s_gcp/#directory-structure","title":"Directory Structure","text":"<pre><code>flask-k3s-demo/\n\u251c\u2500\u2500 app.py\n\u251c\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 Dockerfile\n\u2514\u2500\u2500 flask-deployment.yaml\n</code></pre>"},{"location":"Homelab/k3s_gcp/#apppy","title":"app.py","text":"<pre><code>from flask import Flask, jsonify\nimport os\nimport socket\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return jsonify({\n        'message': 'Hello from K3s on GCP!',\n        'hostname': socket.gethostname(),\n        'version': '1.0.0'\n    })\n\n@app.route('/health')\ndef health():\n    return jsonify({'status': 'healthy'}), 200\n\n@app.route('/info')\ndef info():\n    return jsonify({\n        'pod_name': socket.gethostname(),\n        'pod_ip': socket.gethostbyname(socket.gethostname()),\n        'app_version': '1.0.0'\n    })\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000)\n</code></pre>"},{"location":"Homelab/k3s_gcp/#requirementstxt","title":"requirements.txt","text":"<pre><code>Flask==3.0.0\ngunicorn==21.2.0\n</code></pre>"},{"location":"Homelab/k3s_gcp/#dockerfile","title":"Dockerfile","text":"<pre><code>FROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY app.py .\n\nEXPOSE 5000\n\nCMD [\"gunicorn\", \"--bind\", \"0.0.0.0:5000\", \"--workers\", \"2\", \"app:app\"]\n</code></pre>"},{"location":"Homelab/k3s_gcp/#build-and-push-image","title":"Build and Push Image","text":"<pre><code># Set project ID\nPROJECT_ID=$(gcloud config get-value project)\n\n# Build image\ndocker build -t gcr.io/$PROJECT_ID/flask-k3s-app:v1.0.0 .\n\n# Configure Docker\ngcloud auth configure-docker\n\n# Push to Google Container Registry\ndocker push gcr.io/$PROJECT_ID/flask-k3s-app:v1.0.0\n</code></pre>"},{"location":"Homelab/k3s_gcp/#deployment-without-helm","title":"Deployment Without Helm","text":""},{"location":"Homelab/k3s_gcp/#flask-deploymentyaml","title":"flask-deployment.yaml","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flask-app\n  labels:\n    app: flask-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: flask-app\n  template:\n    metadata:\n      labels:\n        app: flask-app\n    spec:\n      containers:\n      - name: flask-app\n        image: gcr.io/YOUR_PROJECT_ID/flask-k3s-app:v1.0.0\n        ports:\n        - containerPort: 5000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 200m\n            memory: 256Mi\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 5000\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 5000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: flask-app-service\nspec:\n  type: LoadBalancer\n  selector:\n    app: flask-app\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 5000\n</code></pre>"},{"location":"Homelab/k3s_gcp/#deploy-application","title":"Deploy Application","text":"<pre><code># Update YAML with your project ID\nPROJECT_ID=$(gcloud config get-value project)\nsed -i \"s/YOUR_PROJECT_ID/$PROJECT_ID/g\" flask-deployment.yaml\n\n# Deploy\nkubectl apply -f flask-deployment.yaml\n\n# Check status\nkubectl get pods\nkubectl get svc\n\n# Get external IP\nkubectl get svc flask-app-service\n</code></pre>"},{"location":"Homelab/k3s_gcp/#test-application","title":"Test Application","text":"<pre><code># Get external IP\nEXTERNAL_IP=$(kubectl get svc flask-app-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n\n# Test endpoints\ncurl http://$EXTERNAL_IP/\ncurl http://$EXTERNAL_IP/health\ncurl http://$EXTERNAL_IP/info\n</code></pre>"},{"location":"Homelab/k3s_gcp/#useful-commands","title":"Useful Commands","text":""},{"location":"Homelab/k3s_gcp/#cluster-management","title":"Cluster Management","text":"<pre><code># Get nodes\nkubectl get nodes\n\n# Get all resources\nkubectl get all -A\n\n# Cluster info\nkubectl cluster-info\n\n# Node details\nkubectl describe node &lt;node-name&gt;\n</code></pre>"},{"location":"Homelab/k3s_gcp/#pod-management","title":"Pod Management","text":"<pre><code># List pods\nkubectl get pods\n\n# Pod details\nkubectl describe pod &lt;pod-name&gt;\n\n# View logs\nkubectl logs &lt;pod-name&gt;\n\n# Follow logs\nkubectl logs -f &lt;pod-name&gt;\n\n# Logs for all pods with label\nkubectl logs -l app=flask-app --tail=50\n\n# Execute command in pod\nkubectl exec -it &lt;pod-name&gt; -- /bin/bash\n</code></pre>"},{"location":"Homelab/k3s_gcp/#deployment-management","title":"Deployment Management","text":"<pre><code># Scale deployment\nkubectl scale deployment flask-app --replicas=5\n\n# Update image (rolling update)\nkubectl set image deployment/flask-app flask-app=gcr.io/$PROJECT_ID/flask-k3s-app:v1.1.0\n\n# Check rollout status\nkubectl rollout status deployment/flask-app\n\n# Rollout history\nkubectl rollout history deployment/flask-app\n\n# Rollback to previous version\nkubectl rollout undo deployment/flask-app\n\n# Rollback to specific revision\nkubectl rollout undo deployment/flask-app --to-revision=2\n</code></pre>"},{"location":"Homelab/k3s_gcp/#service-management","title":"Service Management","text":"<pre><code># List services\nkubectl get svc\n\n# Service details\nkubectl describe svc flask-app-service\n\n# Get endpoints\nkubectl get endpoints\n</code></pre>"},{"location":"Homelab/k3s_gcp/#resource-management","title":"Resource Management","text":"<pre><code># Apply configuration\nkubectl apply -f deployment.yaml\n\n# Delete resources\nkubectl delete -f deployment.yaml\n\n# Delete specific resource\nkubectl delete deployment flask-app\nkubectl delete service flask-app-service\n\n# Edit resource\nkubectl edit deployment flask-app\n</code></pre>"},{"location":"Homelab/k3s_gcp/#debugging","title":"Debugging","text":"<pre><code># Get events\nkubectl get events --sort-by=.metadata.creationTimestamp\n\n# Check resource usage\nkubectl top nodes\nkubectl top pods\n\n# Port forward to local machine\nkubectl port-forward service/flask-app-service 8080:80\n\n# Describe issues\nkubectl describe pod &lt;pod-name&gt;\n</code></pre>"},{"location":"Homelab/k3s_gcp/#namespace-management","title":"Namespace Management","text":"<pre><code># List namespaces\nkubectl get namespaces\n\n# Create namespace\nkubectl create namespace dev\n\n# Deploy to specific namespace\nkubectl apply -f deployment.yaml -n dev\n\n# Set default namespace\nkubectl config set-context --current --namespace=dev\n</code></pre>"},{"location":"Homelab/k3s_gcp/#configuration","title":"Configuration","text":"<pre><code># View current context\nkubectl config current-context\n\n# View all contexts\nkubectl config get-contexts\n\n# Switch context\nkubectl config use-context &lt;context-name&gt;\n\n# View kubeconfig\nkubectl config view\n</code></pre>"},{"location":"Homelab/k3s_gcp/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Homelab/k3s_gcp/#pod-not-starting","title":"Pod Not Starting","text":"<pre><code># Check pod status\nkubectl describe pod &lt;pod-name&gt;\n\n# Check logs\nkubectl logs &lt;pod-name&gt;\n\n# Check events\nkubectl get events\n</code></pre>"},{"location":"Homelab/k3s_gcp/#service-not-accessible","title":"Service Not Accessible","text":"<pre><code># Check service\nkubectl get svc\nkubectl describe svc flask-app-service\n\n# Check endpoints\nkubectl get endpoints flask-app-service\n\n# Check firewall rules\ngcloud compute firewall-rules list\n</code></pre>"},{"location":"Homelab/k3s_gcp/#image-pull-errors","title":"Image Pull Errors","text":"<pre><code># Verify image exists\ngcloud container images list --repository=gcr.io/$PROJECT_ID\n\n# Check if cluster can access GCR\nkubectl get pods -o yaml | grep imagePullSecrets\n</code></pre>"},{"location":"Homelab/k3s_gcp/#node-issues","title":"Node Issues","text":"<pre><code># Check node status\nkubectl get nodes\nkubectl describe node &lt;node-name&gt;\n\n# SSH into node\ngcloud compute ssh &lt;node-name&gt; --zone=&lt;zone&gt;\n\n# Check K3s service\nsudo systemctl status k3s\nsudo systemctl status k3s-agent\n</code></pre>"},{"location":"Homelab/k3s_gcp/#cleanup","title":"Cleanup","text":""},{"location":"Homelab/k3s_gcp/#delete-application","title":"Delete Application","text":"<pre><code>kubectl delete -f flask-deployment.yaml\n</code></pre>"},{"location":"Homelab/k3s_gcp/#delete-cluster-single-node","title":"Delete Cluster (Single Node)","text":"<pre><code>gcloud compute instances delete k3s-free --zone=us-west1-b\ngcloud compute firewall-rules delete k3s-api k3s-http\n</code></pre>"},{"location":"Homelab/k3s_gcp/#delete-cluster-3-node","title":"Delete Cluster (3-Node)","text":"<pre><code>gcloud compute instances delete k3s-server k3s-agent-1 k3s-agent-2 --zone=us-central1-a\ngcloud compute firewall-rules delete k3s-api k3s-internal\n</code></pre>"},{"location":"Homelab/k3s_gcp/#additional-resources","title":"Additional Resources","text":"<ul> <li>K3s Documentation: https://docs.k3s.io/</li> <li>Kubernetes Documentation: https://kubernetes.io/docs/</li> <li>GCP Free Tier: https://cloud.google.com/free</li> <li>GCP Pricing Calculator: https://cloud.google.com/products/calculator</li> </ul>"},{"location":"Homelab/k3s_gcp/#notes","title":"Notes","text":"<ul> <li>Always use US regions (us-west1, us-central1, us-east1) for free tier eligibility</li> <li>Single e2-micro node is sufficient for learning Kubernetes/K3s</li> <li>Stop instances when not in use to avoid egress charges</li> <li>Use <code>kubectl get all -A</code> regularly to monitor cluster state</li> <li>Keep your kubeconfig file secure</li> <li>Consider using preemptible instances for even lower costs (not eligible for free tier)</li> </ul> <p>Last Updated: October 2025</p>"},{"location":"Homelab/wol/","title":"Wake-on-LAN (WOL) Setup on Ubuntu Laptop Server","text":"<p>This guide explains how to enable and configure Wake-on-LAN (WOL) on a laptop running Ubuntu Server.</p>"},{"location":"Homelab/wol/#1-check-biosuefi-support","title":"\ud83e\udde9 1. Check BIOS/UEFI Support","text":"<ol> <li>Reboot your laptop and enter the BIOS/UEFI setup (usually F2, Del, or Esc).</li> <li>Look for and enable one of the following:</li> <li>Wake on LAN</li> <li>Power on by PCI-E</li> <li>Wake from Network</li> <li>Save and exit.</li> </ol> <p>\u26a0\ufe0f Note: Many laptops only support WOL when plugged into AC power (not on battery).</p>"},{"location":"Homelab/wol/#2-enable-wol-in-ubuntu","title":"\u2699\ufe0f 2. Enable WOL in Ubuntu","text":"<p>Install <code>ethtool</code>: <pre><code>sudo apt update\nsudo apt install ethtool\n</code></pre></p> <p>Check your network interface: <pre><code>ip link\n</code></pre></p> <p>Verify WOL capability: <pre><code>sudo ethtool &lt;interface&gt;\n</code></pre></p> <p>Enable WOL: <pre><code>sudo ethtool -s &lt;interface&gt; wol g\n</code></pre></p> <p>Confirm: <pre><code>sudo ethtool &lt;interface&gt; | grep Wake-on\n</code></pre></p> <p>Expected output: <pre><code>Wake-on: g\n</code></pre></p>"},{"location":"Homelab/wol/#3-make-wol-persistent","title":"\ud83d\udd01 3. Make WOL Persistent","text":"<p>Create a systemd service: <pre><code>sudo nano /etc/systemd/system/wol@.service\n</code></pre></p> <p>Add: <pre><code>[Unit]\nDescription=Wake-on-LAN for %i\nAfter=network.target\n\n[Service]\nType=oneshot\nExecStart=/sbin/ethtool -s %i wol g\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p> <p>Enable and start: <pre><code>sudo systemctl enable wol@&lt;interface&gt;.service\nsudo systemctl start wol@&lt;interface&gt;.service\n</code></pre></p>"},{"location":"Homelab/wol/#4-get-mac-address","title":"\ud83c\udf10 4. Get MAC Address","text":"<pre><code>ip link show &lt;interface&gt; | grep ether\n</code></pre> <p>Example: <pre><code>ether 00:11:22:33:44:55\n</code></pre></p>"},{"location":"Homelab/wol/#5-test-wol","title":"\u26a1 5. Test WOL","text":"<p>On another computer in the same LAN:</p> <p>Install wakeonlan: <pre><code>sudo apt install wakeonlan\n</code></pre></p> <p>Send the magic packet: <pre><code>wakeonlan 00:11:22:33:44:55\n</code></pre></p> <p>The laptop should power on if: - It\u2019s connected via Ethernet - Plugged into power - Properly configured in BIOS</p>"},{"location":"Homelab/wol/#6-laptop-lid-behavior","title":"\ud83d\udcbb 6. Laptop Lid Behavior","text":"<p>By default, closing the lid puts the laptop to sleep, disabling WOL. To prevent this:</p> <p>Edit logind configuration: <pre><code>sudo nano /etc/systemd/logind.conf\n</code></pre></p> <p>Set: <pre><code>HandleLidSwitch=ignore\nHandleLidSwitchDocked=ignore\n</code></pre></p> <p>Apply changes: <pre><code>sudo systemctl restart systemd-logind\n</code></pre></p>"},{"location":"Homelab/wol/#lid-guidelines","title":"Lid Guidelines","text":"Scenario Works with Lid Closed? Notes Shutdown + AC Power \u2705 WOL works fine Suspend (Sleep) \u26a0\ufe0f Depends on hardware On Battery Only \u274c Usually unsupported Running Server Mode \u2705 Use <code>HandleLidSwitch=ignore</code>"},{"location":"Homelab/wol/#notes-tips","title":"\ud83e\udde0 Notes &amp; Tips","text":"<ul> <li>WOL over Wi-Fi is generally not supported on laptops.</li> <li>To check suspend support:   <pre><code>cat /sys/power/mem_sleep\n</code></pre></li> <li><code>s2idle</code>: WOL won't work</li> <li><code>deep</code>: Might work if NIC remains powered</li> <li>Ensure Ethernet LEDs remain lit after shutdown (indicates NIC still powered).</li> </ul>"},{"location":"Homelab/wol/#tldr","title":"\u2705 TL;DR","text":"<ol> <li>Enable WOL in BIOS and Ubuntu.</li> <li>Keep laptop on AC power.</li> <li>Use Ethernet (not Wi-Fi).</li> <li>Set:    <pre><code>HandleLidSwitch=ignore\n</code></pre>    to run with lid closed.</li> <li>Test with:    <pre><code>wakeonlan &lt;MAC_ADDRESS&gt;\n</code></pre></li> </ol>"},{"location":"supervisor_manager/overview/","title":"Supervisor Manager - Overview","text":""},{"location":"supervisor_manager/overview/#what-is-supervisor-manager","title":"\ud83d\ude80 What is Supervisor Manager?","text":"<p>Supervisor Manager is a powerful Python tool designed to simplify the deployment and management of Python applications using Supervisor. It provides an easy-to-use interface for generating supervisor configurations, managing application lifecycles, and automating deployment processes.</p>"},{"location":"supervisor_manager/overview/#key-features","title":"\u2728 Key Features","text":"<ul> <li>\ud83c\udfaf Easy Deployment: Deploy Python applications with a single command</li> <li>\ud83d\udcdd Template System: Pre-built templates for Flask, Streamlit, Django, FastAPI, and more</li> <li>\u2699\ufe0f Program Management: Start, stop, restart, and monitor supervisor programs</li> <li>\ud83d\udd27 Auto-generated Scripts: Automatically creates shell scripts for your applications</li> <li>\ud83d\udcca Log Management: Automatic log file configuration and rotation</li> <li>\ud83c\udfae Interactive Mode: User-friendly interactive interface</li> <li>\ud83d\udd04 Batch Operations: Deploy multiple applications at once</li> </ul>"},{"location":"supervisor_manager/overview/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<p>The Supervisor Manager consists of several key components:</p>"},{"location":"supervisor_manager/overview/#core-classes","title":"Core Classes","text":"<ul> <li><code>SupervisorManager</code>: Main class for managing supervisor configurations and programs</li> <li><code>AppConfig</code>: Data class for application configuration</li> <li><code>SupervisorTemplates</code>: Predefined templates for common application types</li> </ul>"},{"location":"supervisor_manager/overview/#file-structure","title":"File Structure","text":"<pre><code>supervisor_manager/\n\u251c\u2500\u2500 supervisor_manager.py      # Main application logic\n\u251c\u2500\u2500 supervisor_templates.py    # Predefined templates\n\u251c\u2500\u2500 demo_supervisor.py         # Demo and examples\n\u251c\u2500\u2500 example_deployment.py      # Deployment examples\n\u2514\u2500\u2500 SUPERVISOR_MANAGER_README.md # Basic documentation\n</code></pre>"},{"location":"supervisor_manager/overview/#use-cases","title":"\ud83c\udfaf Use Cases","text":""},{"location":"supervisor_manager/overview/#1-web-application-deployment","title":"1. Web Application Deployment","text":"<p>Deploy Flask, Streamlit, Django, or FastAPI applications with proper process management.</p>"},{"location":"supervisor_manager/overview/#2-background-services","title":"2. Background Services","text":"<p>Run Python scripts, data processors, or Telegram bots as managed services.</p>"},{"location":"supervisor_manager/overview/#3-development-to-production","title":"3. Development to Production","text":"<p>Seamlessly move applications from development to production with supervisor.</p>"},{"location":"supervisor_manager/overview/#4-multi-application-management","title":"4. Multi-Application Management","text":"<p>Manage multiple Python applications from a single interface.</p>"},{"location":"supervisor_manager/overview/#supported-application-types","title":"\ud83d\udd27 Supported Application Types","text":"Type Description Default Port Template Flask Web applications 5000 \u2705 Streamlit Data science apps 8501 \u2705 Django Full-stack web apps 8000 \u2705 FastAPI Modern API applications 8000 \u2705 Telegram Bot Bot applications N/A \u2705 Data Processor Background scripts N/A \u2705 Generic Any Python script Custom \u2705"},{"location":"supervisor_manager/overview/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"supervisor_manager/overview/#command-line-usage","title":"Command Line Usage","text":"<pre><code># Deploy a new application\npython supervisor_manager.py deploy my_app /path/to/app.py --type streamlit --port 8501\n\n# Manage programs\npython supervisor_manager.py manage start my_app\npython supervisor_manager.py list\n\n# Interactive mode\npython supervisor_manager.py interactive\n</code></pre>"},{"location":"supervisor_manager/overview/#python-api-usage","title":"Python API Usage","text":"<pre><code>from supervisor_manager import SupervisorManager\nfrom supervisor_templates import SupervisorTemplates\n\n# Create manager\nmanager = SupervisorManager()\n\n# Deploy using template\nconfig = SupervisorTemplates.streamlit_app(\n    name=\"my_app\",\n    app_path=\"/path/to/app.py\",\n    port=8501\n)\nresult = manager.deploy_app(config)\n</code></pre>"},{"location":"supervisor_manager/overview/#generated-files","title":"\ud83d\udcc1 Generated Files","text":"<p>When you deploy an application, Supervisor Manager creates:</p> <pre><code>/home/gws/deployment/\n\u251c\u2500\u2500 {app_name}.sh              # Shell script to run the app\n\u2514\u2500\u2500 {app_name}/                # App directory\n    \u251c\u2500\u2500 {app_name}.log         # Stdout log\n    \u2514\u2500\u2500 {app_name}_err.log     # Stderr log\n\n/home/gws/supervisor_configs/\n\u2514\u2500\u2500 {app_name}.conf            # Supervisor configuration\n\n/etc/supervisor/conf.d/\n\u2514\u2500\u2500 {app_name}.conf            # Deployed supervisor config\n</code></pre>"},{"location":"supervisor_manager/overview/#workflow","title":"\ud83d\udd04 Workflow","text":"<ol> <li>Configure: Define your application settings</li> <li>Generate: Create supervisor configuration and shell scripts</li> <li>Deploy: Copy configuration to supervisor directory</li> <li>Manage: Start, stop, restart, and monitor applications</li> <li>Monitor: Check logs and application status</li> </ol>"},{"location":"supervisor_manager/overview/#benefits","title":"\ud83c\udfaf Benefits","text":"<ul> <li>Simplified Deployment: No need to manually write supervisor configurations</li> <li>Consistent Setup: Standardized configuration across all applications</li> <li>Easy Management: Single interface for all supervisor operations</li> <li>Error Prevention: Validates configurations before deployment</li> <li>Log Management: Automatic log rotation and management</li> <li>Environment Handling: Proper virtual environment activation</li> </ul>"},{"location":"supervisor_manager/overview/#next-steps","title":"\ud83d\udd17 Next Steps","text":"<ul> <li>Installation Guide - Set up Supervisor Manager</li> <li>Usage Examples - Learn how to use the tool</li> <li>API Reference - Detailed API documentation</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"}]}